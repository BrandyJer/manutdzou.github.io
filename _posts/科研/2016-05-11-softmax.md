---
layout: post
title: Softmax回归
category: 科研
tags: 深度学习
keywords: 理论
description: 
---


# 深度学习Softmax回归:

Softmax回归模型，该模型是logistic回归模型在多分类问题上的推广，在多分类问题中，类标签 $y$ 可以取两个以上的值。Softmax回归模型对于诸如MNIST手写数字分类等问题是很有用的，该问题的目的是辨识10个不同的单个数字。Softmax回归是有监督的，不过后面也会介绍它与深度学习/无监督学习方法的结合。（MNIST 是一个手写数字识别库，由NYU 的Yann LeCun 等人维护。http://yann.lecun.com/exdb/mnist/）

回想一下在 logistic 回归中，我们的训练集由 $m$ 个已标记的样本构成：\{ (x^{(1)}, y^{(1)}), \ldots, (x^{(m)}, y^{(m)}) \} ，其中输入特征x^{(i)} \in \Re^{n+1}。（我们对符号的约定如下：特征向量 \textstyle x 的维度为 \textstyle n+1，其中 \textstyle x_0 = 1 对应截距项 。） 由于 logistic 回归是针对二分类问题的，因此类标记 y^{(i)} \in \{0,1\}。假设函数(hypothesis function) 如下：

$\[\left\{ {\left( {{x^{\left( 1 \right)}},{y^{\left( 1 \right)}}} \right),...,\left( {{x^{\left( m \right)}},{y^{\left( m \right)}}} \right)} \right\}\]$